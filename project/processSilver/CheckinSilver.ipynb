{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Imputer\n",
    "import pyspark.sql.functions as F\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Checkins to Silver\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:3.1.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkin_data(spark, path):\n",
    "    schema = StructType([\n",
    "        StructField(\"business_id\", StringType(), True),\n",
    "        StructField(\"date\", StringType(), True)\n",
    "    ])\n",
    "    return spark.read.json(path, schema=schema)\n",
    "\n",
    "df = load_checkin_data(spark, \"D:/Project/delta_lake/bronze/yelp_academic_dataset_checkin.json\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dates(df):\n",
    "    # Split the date string into individual timestamps\n",
    "    df = df.withColumn(\"date_array\", split(col(\"date\"), \", \"))\n",
    "    \n",
    "    # Explode the array to create individual rows for each checkin\n",
    "    df = df.withColumn(\"checkin_timestamp\", explode(col(\"date_array\")))\n",
    "    \n",
    "    # Convert to timestamp and extract components\n",
    "    df = df.withColumn(\"checkin_timestamp\", to_timestamp(col(\"checkin_timestamp\"))) \\\n",
    "        .withColumn(\"year\", year(col(\"checkin_timestamp\"))) \\\n",
    "        .withColumn(\"month\", month(col(\"checkin_timestamp\"))) \\\n",
    "        .withColumn(\"day\", dayofmonth(col(\"checkin_timestamp\"))) \\\n",
    "        .withColumn(\"hour\", hour(col(\"checkin_timestamp\"))) \\\n",
    "        .withColumn(\"day_of_week\", date_format(col(\"checkin_timestamp\"), \"EEEE\"))\n",
    "    \n",
    "    return df.drop(\"date_array\", \"date\")\n",
    "\n",
    "df = transform_dates(df)\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # Time period categorization\n",
    "    df = df.withColumn(\"time_period\",\n",
    "        when((col(\"hour\") >= 6) & (col(\"hour\") < 12), \"Morning\")\n",
    "        .when((col(\"hour\") >= 12) & (col(\"hour\") < 17), \"Afternoon\")\n",
    "        .when((col(\"hour\") >= 17) & (col(\"hour\") < 22), \"Evening\")\n",
    "        .otherwise(\"Night\"))\n",
    "    \n",
    "    # Weekend flag\n",
    "    df = df.withColumn(\"is_weekend\",\n",
    "        when(col(\"day_of_week\").isin([\"Saturday\", \"Sunday\"]), True)\n",
    "        .otherwise(False))\n",
    "    \n",
    "    # Business checkin frequency\n",
    "    window_daily = Window.partitionBy(\"business_id\", \"year\", \"month\", \"day\")\n",
    "    df = df.withColumn(\"daily_checkins\", count(\"*\").over(window_daily))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = feature_engineering(df)\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df):\n",
    "    # Daily aggregations\n",
    "    daily_metrics = df.groupBy(\"business_id\", \"year\", \"month\", \"day\") \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"total_checkins\"),\n",
    "            countDistinct(\"hour\").alias(\"unique_hours\"),\n",
    "            sum(when(col(\"is_weekend\"), 1).otherwise(0)).alias(\"weekend_checkins\"),\n",
    "            sum(when(col(\"time_period\") == \"Morning\", 1).otherwise(0)).alias(\"morning_checkins\"),\n",
    "            sum(when(col(\"time_period\") == \"Afternoon\", 1).otherwise(0)).alias(\"afternoon_checkins\"),\n",
    "            sum(when(col(\"time_period\") == \"Evening\", 1).otherwise(0)).alias(\"evening_checkins\"),\n",
    "            sum(when(col(\"time_period\") == \"Night\", 1).otherwise(0)).alias(\"night_checkins\")\n",
    "        )\n",
    "    \n",
    "    return daily_metrics\n",
    "\n",
    "df_metrics = calculate_metrics(df)\n",
    "df_metrics.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    df = df.filter(\n",
    "        (length(col(\"business_id\")) > 0) &\n",
    "        (col(\"checkin_timestamp\").isNotNull()) &\n",
    "        (col(\"year\") >= 2004) &  # Yelp founding year\n",
    "        (col(\"year\") <= year(current_date())) &\n",
    "        (col(\"hour\").between(0, 23))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df = validate_data(df)\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_checks(df):\n",
    "    null_counts = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) \n",
    "                           for c in df.columns])\n",
    "    \n",
    "    time_dist = df.groupBy(\"time_period\") \\\n",
    "        .agg(count(\"*\").alias(\"checkin_count\")) \\\n",
    "        .orderBy(\"time_period\")\n",
    "    \n",
    "    weekday_dist = df.groupBy(\"day_of_week\") \\\n",
    "        .agg(count(\"*\").alias(\"checkin_count\")) \\\n",
    "        .orderBy(\"day_of_week\")\n",
    "    \n",
    "    print(\"Null Counts:\")\n",
    "    null_counts.show()\n",
    "    print(\"\\nTime Period Distribution:\")\n",
    "    time_dist.show()\n",
    "    print(\"\\nWeekday Distribution:\")\n",
    "    weekday_dist.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = quality_checks(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed checkins\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .save(\"D:/Project/delta_lake/silver/checkins_detailed\")\n",
    "\n",
    "# Save daily metrics\n",
    "df_metrics.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .save(\"D:/Project/delta_lake/silver/checkins_metrics\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
